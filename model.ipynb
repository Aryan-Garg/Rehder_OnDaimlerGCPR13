{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Understanding how Markovian models perform for autonomous driving(perception) purposes </center></h1>\n",
    "\n",
    "### Paper: Goal Directed Pedestrian Prediction. Eike Rehder, ICCV15 \n",
    "### Dataset: Daimler Dataset GCPR13 \n",
    "\n",
    "> Dr. Renu M. Rameshan  \n",
    "> Dr. Amit S. Unde  \n",
    "> Aryan Garg  \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+]Loading essential packages...\n",
      "[+]Loaded OpenCV version 4.5.2 @ Thu Sep 30 12:41:41 2021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For all modules that produce a not-found / needs update error:\n",
    "# In the notebook, before importing, write after\n",
    "# Replacing angular brackets with module name:\n",
    "# ! pip install <package-name-as-per-package's-documentation>\n",
    "\n",
    "import cv2 \n",
    "from PIL import Image\n",
    "import imutils\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "print(f\"[+]Loading essential packages...\")\n",
    "print(f\"[+]Loaded OpenCV version {cv2.__version__} @ {time.asctime(time.localtime(time.time()))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preProcessData:\n",
    "    \n",
    "    def readData(self, trainDataP):\n",
    "        try:\n",
    "            self.dirs = [f for f in listdir(trainDataP)]\n",
    "            for directory in self.dirs:\n",
    "                newPath = self.trainDataPath + directory + \"\\\\RectGrabber\\\\\"\n",
    "                files = [f for f in listdir(newPath) if isfile(join(newPath, f))]\n",
    "                self.allTrainingData[directory] = files\n",
    "            #print(self.allTrainingData)\n",
    "            return True\n",
    "        \n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            print(\"Couldn't read data. Check file paths and file health!\")\n",
    "            return False\n",
    "        \n",
    "    \n",
    "    \n",
    "    def showFrames(self, windowName, imglst):\n",
    "        if len(windowName) != len(imglst):\n",
    "            print(f\"windowName list len: {len(windowName)} not equal to imglst len: {len(imglst)}\")\n",
    "            return False \n",
    "        \n",
    "        for i in range(len(windowName)):\n",
    "            cv2.imshow(f\"{windowName[i]}\", imglst[i])\n",
    "        \n",
    "        k = cv2.waitKey(0)\n",
    "        if k is not None:\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    def showSampleImages(self, folderName = \"2012-06-05_165931\"):\n",
    "        ### TODO: Decrease Image size\n",
    "        print(\"[+] Logging sample images' details\\n---------------------\")\n",
    "        for i in range(1,10,2): \n",
    "            img_left = self.allTrainingData[folderName][i-1]\n",
    "            img_right = self.allTrainingData[folderName][i]\n",
    "\n",
    "            try:\n",
    "                imgL = cv2.imread(self.trainDataPath + folderName + \"\\\\RectGrabber\\\\\" + img_left)\n",
    "                imgR = cv2.imread(self.trainDataPath + folderName + \"\\\\RectGrabber\\\\\" + img_right)\n",
    "                \n",
    "                imgL = cv2.resize(imgL, (600,450))\n",
    "                imgR = cv2.resize(imgR, (600,450))\n",
    "                print(f\"{(i//2) + 1}. Image names: {img_left} & {img_right}\\n\\t\\tShape-L: {imgL.shape}     Shape-R: {imgR.shape}\\n\")\n",
    "                \n",
    "                if not self.showFrames([\"Left frame\", \"Right frame\"], [imgL, imgR]):\n",
    "                    print(f\"Couldn't show sample images from showSampleImages function\")\n",
    "            \n",
    "            except Exception as err:\n",
    "                print(err)\n",
    "                if imgL is None:\n",
    "                    print(f\"[!]Couldn't load L-image: {img_left}\")\n",
    "                if imgR is None:\n",
    "                    print(f\"[!]Couldn't load R-image: {img_right}\")\n",
    "                continue\n",
    "                \n",
    "        print(\"---------------------\\n[+] Finished viewing initial samples.\")\n",
    "\n",
    "    \n",
    "    \n",
    "    def frameFromLR(self):\n",
    "        ### TODO: Will have to refer to the 14th paper later\n",
    "        ### For now standard\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def removeNoise(self):\n",
    "        ### TODO: Future optimization\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def createVideo(self, folderNum):\n",
    "        try:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "            video = cv2.VideoWriter('out_video.avi', fourcc, 30.0, self.allTrainingData[folderNum][0].shape)\n",
    "        \n",
    "            for imgL, imgR in self.allTrainingData[folderNum][:121]:\n",
    "                video.write(imgL)\n",
    "\n",
    "            video.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(f\"[+]Video out_video.avi released\")\n",
    "            \n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            print(f\"Possible fixes:\\n1. See if DIVX is compatible with your machine\\n2. Use a media player that supports .avi\\n\\\n",
    "                    3. Match the shape of frames with the video\")\n",
    "\n",
    "    def detectPedestriansAnnotations(self, dirName, imageList):\n",
    "        '''\n",
    "            \n",
    "            Brief: Making bounding boxes using the annotations provided in dataset\n",
    "            \n",
    "            Need to use SQL queries here to extract info!!! (.db files are present)\n",
    "            \n",
    "        '''\n",
    "        print(\"\\nCreating Bounding Boxes...\")\n",
    "        print(f\"\\nDRAWING FOR {dirName}\")\n",
    "        path_ = 'C:\\\\Users\\\\HP\\\\Desktop\\Research\\\\Trajectory_Markov_Research\\\\Implementations\\\\Dataset_Dailmer\\\\TrainingData_Annotations\\\\'\n",
    "        path_ += str(dirName)+\"\\\\LabelData\\\\\"\n",
    "        # creating file path\n",
    "        dbfile = path_ + \"meas.db\"\n",
    "        \n",
    "        toRet = []\n",
    "        with open(dbfile) as f:\n",
    "            \n",
    "            rd = f.readlines()\n",
    "            # Text formatting params:\n",
    "            font                   = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "            fontScale              = 0.7\n",
    "            fontColor              = (255, 255, 255)\n",
    "            lineType               = 2\n",
    "            for i in range(len(rd)):\n",
    "                imgName = \"\"\n",
    "                box_cos = \"\"\n",
    "                \n",
    "                if \"img\" in rd[i]:\n",
    "                    imgName = rd[i][:-1]\n",
    "                    \n",
    "                    if i+6 < len(rd):\n",
    "                        box_cos = rd[i+6].split()\n",
    "                        if len(box_cos) != 4:\n",
    "                            continue\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    imgName = \"imgrect_\"+imgName[4:] \n",
    "                    #print(f\"{imgName}:{box_cos}\")\n",
    "                    \n",
    "                    img = cv2.imread( \"C:\\\\Users\\\\HP\\\\Desktop\\\\Research\\\\Trajectory_Markov_Research\\\\Implementations\\Dataset_Dailmer\\\\Data\\\\TrainingData\\\\\" \n",
    "                                     + dirName + \"\\\\RectGrabber\\\\\" + imgName )\n",
    "                    \n",
    "                    if img is None:\n",
    "                        print(\"[-]Image could not load!\")\n",
    "                        continue\n",
    "                \n",
    "                    \n",
    "                    box_cos = [int(e) for e in box_cos]\n",
    "                    \n",
    "                    if dirName not in self.detectedDataBox:\n",
    "                        self.detectedDataBox[dirName] = []\n",
    "                        \n",
    "                    self.detectedDataBox[dirName].append(box_cos) \n",
    "                    x,y,a,b = box_cos # Top left: (x,y) ; Bottom Right: (a,b)\n",
    "                    cv2.rectangle(img, (x, y), (a,b), (0, 255, 0), 2)\n",
    "                    #cv2.putText(img,'Person', (int(x),int(y)), font, fontScale,fontColor,lineType)\n",
    "                    \n",
    "                    #cv2.imshow(\"Bounding Box from Annotations\", img)\n",
    "                    #cv2.waitKey(0)\n",
    "                    \n",
    "                    toRet.append(img)\n",
    "            \n",
    "            f.close()\n",
    "            return toRet\n",
    "\n",
    "    \n",
    "    def detectPedestriansHOG(self, dirName, imageList): \n",
    "        '''\n",
    "            Brief: \n",
    "                    Standard Histogram Oriented Gradients Object Detection provided by openCV. \n",
    "                    (Dalal & Triggs)\n",
    "            |\n",
    "            Param:\n",
    "                    frame -> For which pedestrian detection must be done\n",
    "                    \n",
    "            Returns:\n",
    "                    Frame with a green bounding box around pedestrians\n",
    "        '''\n",
    "        \n",
    "        toRet = []             # This list will become the object detected data list's part\n",
    "        \n",
    "        # Text formatting params:\n",
    "        font                   = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "        fontScale              = 0.7\n",
    "        fontColor              = (255, 255, 255)\n",
    "        lineType               = 2\n",
    "        \n",
    "        # Initialize standard HOG people detector\n",
    "        hog = cv2.HOGDescriptor()\n",
    "        hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "        \n",
    "        for imgName in imageList:\n",
    "            img = cv2.imread( self.trainDataPath + dirName + \"\\\\RectGrabber\\\\\" + imgName )\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "                \n",
    "            img = cv2.resize(img, (600, 450))\n",
    "            (rects, weights) = hog.detectMultiScale(img, winStride=(4, 4), padding=(8, 8), scale=1.1)\n",
    "            \n",
    "            for (x, y, w, h) in rects:\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.putText(img,'Person', (x,y), font, fontScale,fontColor,lineType)\n",
    "            \n",
    "            toRet.append(img)\n",
    "                \n",
    "            #if not self.showFrames([\"Bounding Box\"], [img]):\n",
    "             #   print(f\"Couldn't show pedestrian detected image: {img}\")\n",
    "            \n",
    "        \n",
    "        return toRet\n",
    "           \n",
    "    \n",
    "    def __init__(self):\n",
    "        ### Change filepath according to your machine config\n",
    "        self.trainDataPath = \"C:\\\\Users\\\\HP\\\\Desktop\\\\Research\\\\Trajectory_Markov_Research\\\\Implementations\\Dataset_Dailmer\\\\Data\\\\TrainingData\\\\\"\n",
    "        self.dirs = []\n",
    "        self.allTrainingData = dict()\n",
    "        if self.readData(self.trainDataPath):\n",
    "            #self.showSampleImages()\n",
    "            self.detectedData = {}\n",
    "            self.detectedDataBox = {} # Contains TL cos and BR cos of a frame (directory-wise)\n",
    "            doOneDir = True\n",
    "            for key in self.allTrainingData:\n",
    "                if doOneDir:\n",
    "                    self.detectedData[key] = self.detectPedestriansAnnotations(key, self.allTrainingData[key])\n",
    "                    cv2.destroyAllWindows()\n",
    "                    break\n",
    "                else:\n",
    "                    self.detectedData[key] = self.detectPedestriansAnnotations(key, self.allTrainingData[key])\n",
    "                    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    '''\n",
    "    Brief:\n",
    "        Goal Directed Pedestrian Prediction \n",
    "        (A markovian approach for pedestrian trajectory prediction)\n",
    "        \n",
    "    Receives:\n",
    "        Pre-processed and pedestrain detected data from preProcessData class\n",
    "        \n",
    "    Returns:\n",
    "        Predicted Trajectory of each pedestrian in scene\n",
    "                \n",
    "    '''\n",
    "    \n",
    "    # State Transition stuff ahead:\n",
    "    def compute_X(self, dirName = '2012-04-02_115542', numFramesToObserve = 90):\n",
    "        # COMPUTING ONLY FOR THE TL PIXEL OF RECTANGLE \n",
    "        for i in range(1, numFramesToObserve):\n",
    "            x1, y1, a1, b1 = self.dfBox[dirName][i-1]\n",
    "            x2, y2, a2, b2 = self.dfBox[dirName][i]\n",
    "            vx = (x2 - x1) * self.fps    # TODO: Use more valid points to compute an average velocity\n",
    "            vy = (y2 - y1) * self.fps\n",
    "            #print(f\"*** Frames {i-1} and {i} ***\\nvx: {vx} px/sec\\nvy: {vy} px/sec\")\n",
    "            psi = 0\n",
    "            if (x2-x1) != 0:\n",
    "                psi = math.atan(  (y2-y1) / (x2-x1) ) # Slope \n",
    "            #print(f\"phi_t: {math.degrees(psi)} degrees\\n\")\n",
    "            self.uni.append([vx, vy, 0])\n",
    "            self.X.append([x1 + vx/self.fps, y1 + vy/self.fps, 0 + psi]) # Xt = Xt-1 + u(v_t, psi_t) \n",
    "        self.eq3_dist_X()\n",
    "    \n",
    "    def eq3_dist_X(self):\n",
    "        '''\n",
    "            phi_t = p( X_t | X_t-1 )\n",
    "            p(Xt|Xt−1) = p(Xt−1) ⊗ p(u(vt, ψt))\n",
    "        '''\n",
    "        self.distX = np.zeros(shape=(640, 1176))\n",
    "        n = len(self.X)\n",
    "        \n",
    "        for i in range(n):\n",
    "            self.distX[int(self.X[i][1])][int(self.X[i][0])] += 1 / n\n",
    "        \n",
    "        #print(self.distX)\n",
    "        #print(self.distUni)\n",
    "        \n",
    "        #plt.subplot(1,2,1)\n",
    "        #plt.imshow(self.distX)\n",
    "        #plt.subplot(1,2,2)\n",
    "        #plt.imshow(self.distUni)\n",
    "        #plt.show()\n",
    "        # Convolve the two grid distributions\n",
    "        #self.Xt_given_Xt_1 = conv_pmf = signal.fftconvolve(self.distX, self.distUni, 'same')\n",
    "        \n",
    "        #print(f\"P(Xt|Xt-1) = P(Xt-1) * p(u(vt,psit)) =\\n{self.Xt_given_Xt_1}\")\n",
    "        \n",
    "        #for i in range(640):\n",
    "        #    for j in range(1176):           \n",
    "        #        if self.Xt_given_Xt_1[i][j] >= 1:\n",
    "        #            print(f\"cell({i},{j})'s p(Xt|Xt-1) = {self.Xt_given_Xt_1[i][j]}\\nNOT POSSIBLE! RE-CHECK CONVOLUTION\")\n",
    "                \n",
    "        #plt.imshow(disp)\n",
    "        #plt.show()\n",
    "        self.eq4()\n",
    "    \n",
    "    def discretization_2_grid(self, p, x, y):\n",
    "        '''\n",
    "            Consider 1x1 cells -> assign probability(from incremental distribution) to each cell\n",
    "            At the end: A (the convolution filter mask) is obtained \n",
    "        '''\n",
    "        self.A[int(y)][int(x)] = p\n",
    "        \n",
    "    \n",
    "    \n",
    "    def mean_var(self, samples):\n",
    "        mean = sum(samples) / len(samples)\n",
    "        var = 0\n",
    "        for e in samples:\n",
    "            var += (e - mean)**2\n",
    "        var /= len(samples)-1 \n",
    "        return mean, var\n",
    "    \n",
    "    \n",
    "    def vonMises(self, samples):\n",
    "        R = 0                      # 1/N * Summation{e^i.\\theta}\n",
    "        for i in range(len(samples)):\n",
    "            R += math.cos((i+1)*samples[i]) + 1j*math.sin((i+1)*samples[i])\n",
    "        \n",
    "        Rbar = np.abs(R)/len(samples)\n",
    "        kappa_v = (2*Rbar - (Rbar**3)) / (1 - (Rbar**2)) # This is an approximation for fast computation only!\n",
    "        \n",
    "        # TODO: Find closer approximation from Bessel function or Ap^-1\n",
    "        return Rbar, kappa_v\n",
    "    \n",
    "    \n",
    "    def eq4(self):\n",
    "        '''\n",
    "        Model the incremental distribution:\n",
    "            This is p(u(v, psi)) effectively...\n",
    "            \n",
    "            p(∆x, ∆y, ∆ψ) ∝  exp(−(∆x−∆tv cos(ψ))^2/2σ_v^2)\n",
    "                            .exp(−(∆y−∆tv sin(ψ))^2/2σ_v^2)\n",
    "                            .exp(κ∆ψ cos(∆ψ))\n",
    "                            .exp(κv cos(∠(∆y, ∆x) − ψ))\n",
    "                            \n",
    "        Then call self.discretization_2_grid() to get A (the convolution filter mask)\n",
    "        Then call eq5 to get phi_t using A and phi_t-1\n",
    "        \n",
    "        v   -> Normal Dist.             \n",
    "        psi -> circular Normal Dist.\n",
    "        '''\n",
    "        # p[x][y][psi] = model it!!!\n",
    "        vx_mu, vx_var = self.mean_var([e[0] for e in self.uni])\n",
    "        vy_mu, vy_var = self.mean_var([e[1] for e in self.uni])\n",
    "        psi_mu, psi_kappa = self.vonMises([e[2] for e in self.X])\n",
    "        \n",
    "        kappa_nonAligned = 1   # TODO: Figure out if this can be found from the data or is a free parameter\n",
    "        \n",
    "        # TODO: Now find p(del_x, del_y, del_psi)\n",
    "        x,y,z = self.X[-1] # Get filter: A, from last observed position-orientation tuple\n",
    "        # Keeping to a region of -20 to +20\n",
    "        for i in range(-20, 21):\n",
    "            for j in range(-20, 21):\n",
    "                xprev = x + i\n",
    "                yprev = y + j\n",
    "                zprev = 0\n",
    "        \n",
    "                #xprev,yprev,zprev = predicted_df.X[-2]\n",
    "                \n",
    "                k = 1/100000 # Constant of proportionality        -------------> HUGE BUG!!!!!!! \n",
    "                # For now take k to be extremely huge so that everything falls in 0 -> 1\n",
    "                \n",
    "                P_del_xyz = k\n",
    "                P_del_xyz *= math.exp(-((abs(x-xprev) - vx_mu/self.fps)**2)/(2*vx_var)) \n",
    "                #print(self.P_delDist, math.exp(-(((x-xprev) - vx_mu/self.fps)**2)/(2*vx_var)) )\n",
    "                P_del_xyz *= math.exp(-((abs(y-yprev) - vy_mu/self.fps)**2)/(2*vy_var)) \n",
    "                #print(self.P_delDist,  math.exp(-(((y-yprev) - vy_mu/self.fps)**2)/(2*vy_var)))\n",
    "                \n",
    "                P_del_xyz *= math.exp(psi_kappa * math.cos(z - zprev))\n",
    "                #print(self.P_delDist, psi_kappa )\n",
    "                \n",
    "                angle = 0 # goes in non-alaigned term\n",
    "                if  x-xprev == 0:\n",
    "                    angle = math.pi/2 # arctan(infinity) is pi/2\n",
    "                    if y - yprev < 0:\n",
    "                        angle *= -1 # arctan(-inf) is -pi/2\n",
    "                else:    \n",
    "                    angle = math.atan((y-yprev)/(x-xprev))\n",
    "                \n",
    "                P_del_xyz *= math.exp( kappa_nonAligned * math.cos(angle - z) )\n",
    "                #print(P_del_xyz,  math.exp( kappa_nonAligned * math.cos(angle - z)))\n",
    "                self.discretization_2_grid(P_del_xyz, x+i, y+j)                      \n",
    "        print(f\"Filter A computed!\")\n",
    "        \n",
    "        plt.figure(figsize = (16,12))\n",
    "        plt.title(\"Filter A\")\n",
    "        plt.imshow(self.A)\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def eq5(self):\n",
    "        '''\n",
    "            Φt ∝ A ⊗ Φt−1\n",
    "            where Φt = P( Xt | Xt-1 ) {contained in self.Xt_given_Xt_1} \n",
    "            Convolve here\n",
    "            \n",
    "            For ex:\n",
    "            #self.Xt_given_Xt_1 = conv_pmf = signal.fftconvolve(self.distX, self.A, 'same')\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def eq6(self):\n",
    "        '''\n",
    "            Invert distribution in 4 to get (B)           [A^(-1)]\n",
    "            *** For backward prediction steps from XT ***\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def eq7(self):\n",
    "        '''\n",
    "            Carry out forward and backward steps to get each p(Xt | X0, XT) acc. to:\n",
    "            p(Xt|X0, XT ) ∝ Φ+t Φ−t\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    # Location Prior stuff ahead\n",
    "    def eq8(self):\n",
    "        '''\n",
    "            Forward step:\n",
    "            Φ+t ∝ p(Xt|Θt)(A ⊗ Φ+t−1)\n",
    "            \n",
    "            where Θt is the online map\n",
    "                  p(X|θi) is the location prior (call eq10 here)\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def eq9(self):\n",
    "        '''\n",
    "            Backward step:\n",
    "            Φ−t−1 ∝ p(Xt|Θt)(A^(−1) ⊗ Φ−t)\n",
    "            \n",
    "            call eq10 from here\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def eq10(self):\n",
    "        '''\n",
    "            Computes Location prior: p(X|θi) acc to:\n",
    "            \n",
    "            Single Layer Perceptron: \n",
    "            p(X|θi) = 1 / 1 + exp (−a^T . θ_i)\n",
    "            \n",
    "            where a^T represents weighting params for different features. \n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def eq11(self):\n",
    "        '''\n",
    "            Path Distribution: \n",
    "            p(XM|X0, XT , Θt) = 1 −PI[(M) <-- (t˜=0)](1 − p(Xt˜|X0, XT , Θt))\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def eq12(self):\n",
    "        '''\n",
    "            Cost function to get best weighting params, i.e, a:\n",
    "            J(a) = −Summation[ ζi ∈ Xj ] Summation[ Xj ∈ ζi ] log(p(X = Xj |X0, XT , Θt))\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    # Goal Distribution XT Estimation ahead\n",
    "    def eq13(self):\n",
    "        '''\n",
    "            p(Xt) ::= estimated distribution for the pedestrian’s state at time = t. \n",
    "            p(X−t|X0, XT , Θt) ::= the distribution of that state obtained from prediction at t-1. \n",
    "        \n",
    "            [!] After Assumption: Independence\n",
    "            Can obtain:\n",
    "        \n",
    "                pX− (X−t|X0, XT , Θt) ∝ pX− (X0, XT , Θt|X−t)p(X−t)\n",
    "        \n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def eq14(self):\n",
    "        '''\n",
    "            p(XT ) ∝ Integral of pX− (X0, XT , Θt|Xt).p(Xt).dX\n",
    "            \n",
    "            [+] Evaluated for the individual particles and the result is used for reweighting\n",
    "            Next TODO: Unlikely particles are discarded and randomly resampled at other locations.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def __init__(self, bb_Images, bb_cos):\n",
    "        self.df = bb_Images\n",
    "        self.dfBox = bb_cos\n",
    "        self.grid = np.zeros(shape=(640, 1176)) # Grid\n",
    "        self.fps = 30                          # fps\n",
    "        self.X = []                            # Contains last t positions & orientations: (x_t, y_t, psi_t)\n",
    "        self.distX = None                      # Contains X's distribution on grid\n",
    "        self.uni = []                          # Contains unicycle vector of motion: u(vt, psi_t) \n",
    "        self.distUni = None                    # Contains uni's distribution on grid as per X's co-ordinates\n",
    "        self.Xt_given_Xt_1 = None              # Contains distribution: P(X_t | X_t-1)\n",
    "        self.px0 = 0\n",
    "        self.XT = None                         # Latent Variable: Gaussian Mixture Model + Particle Filter\n",
    "        self.A = np.zeros(shape=(640, 1176))\n",
    "        for key in self.df:\n",
    "            self.compute_X(key)  # Watch 1 sec to estimate X\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class analytics:\n",
    "    '''\n",
    "    Brief:\n",
    "        Analyzes predicted trajectories against ground truth.\n",
    "        \n",
    "    Receives:\n",
    "        Predicted trajectories from model class\n",
    "        \n",
    "    Displays:\n",
    "        Accuracy and evaluation metrics. And other visual-aids for analysis of the model\n",
    "                \n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating Bounding Boxes...\n",
      "\n",
      "DRAWING FOR 2012-04-02_115542\n"
     ]
    }
   ],
   "source": [
    "df = preProcessData()                       # Remove noise, use paper 14, Detect pedestrians and then pass to model\n",
    "#print(df.detectedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter A computed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted_df = model(df.detectedData, df.detectedDataBox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointers/Terminolgy I'm using:\n",
    "\n",
    "#### Grid distribution => probability distribution of grid / a probability value is assigned to cell (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
