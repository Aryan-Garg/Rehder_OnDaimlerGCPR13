{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> Understanding how Markovian models perform for autonomous driving(perception) purposes </center></h1>\n",
    "\n",
    "### Paper: Goal Directed Pedestrian Prediction. Eike Rehder, ICCV15 \n",
    "### Dataset: Daimler Dataset GCPR13 \n",
    "\n",
    "#### Implemented by:\n",
    "> Aryan Garg  \n",
    "> Dr. Amit S. Unde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading https://files.pythonhosted.org/packages/3f/d3/ecb4d108f6c1041d24842a345ee0123cd7f366ba75cf122601e856d42ba2/imutils-0.5.4.tar.gz\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (setup.py): started\n",
      "  Building wheel for imutils (setup.py): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-cp36-none-any.whl size=25862 sha256=1fba8f3e21c6085d051c04bc0975ac2050381934ccfde15c8d1ddf9d08d7b1c8\n",
      "  Stored in directory: C:\\Users\\HP\\AppData\\Local\\pip\\Cache\\wheels\\db\\23\\45\\fc7424906880ffa9577a2a428b961f2b79e0e21d9f71e7e6bc\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n",
      "[+]Loaded essential packages\n",
      "[+]Loaded OpenCV version 4.5.2 @ Fri Sep 17 12:14:13 2021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "from PIL import Image\n",
    "import imutils\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import sys\n",
    "\n",
    "print(f\"[+]Loaded essential packages\\n\\\n",
    "[+]Loaded OpenCV version {cv2.__version__} @ {time.asctime(time.localtime(time.time()))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preProcessData:\n",
    "    \n",
    "    def readData(self, trainDataP):\n",
    "        #dirs = [f for f in listdir(trainDataP)]\n",
    "        #allTrainingData = []\n",
    "        #for directory in dirs:\n",
    "        #    newPath = trainDataP + directory + \"\\\\RectGrabber\\\\\"\n",
    "        #    files = [f for f in listdir(newPath) if isfile(join(newPath, f))]\n",
    "        #    allTrainingData.append(files)\n",
    "        #self.showSampleImages()\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def showFrame(self, windowName, img):\n",
    "        cv2.imshow(f\"{windowName}\", img)\n",
    "        k = cv2.waitKey(0)\n",
    "        if k is not None:\n",
    "            cv2.destroyWindow(f\"{windowName}\")\n",
    "        \n",
    "        \n",
    "    def showSampleImages(self):\n",
    "        ### TODO: Use data from allTrainingData list in the future\n",
    "        lstPass = []\n",
    "        \n",
    "        #print(\"[+]Logging sample images' details\\n---------------------\")\n",
    "        for i in range(1,241,2): # This is hardcoded!!! Change it\n",
    "            img_left = filenames[i-1]\n",
    "            img_right = filenames[i]\n",
    "\n",
    "            try:\n",
    "                imgL = cv2.imread(trainDataPath+img_left)\n",
    "                imgR = cv2.imread(trainDataPath+img_right)\n",
    "                \n",
    "                # Resize images\n",
    "                imLeft = cv2.resize(imgL, (64, 128) ) \n",
    "                imRight = cv2.resize(imgR, (64, 128))\n",
    "                \n",
    "                print(f\"{(i//2) + 1}. Image names: {img_left} & {img_right}\\n\\t\\tShape-L: {imLeft.shape}     \\\n",
    "                        Shape-R: {imRight.shape}\\n\")\n",
    "                lstPass.append([imLeft, imRight])\n",
    "                \n",
    "                #cv2.imshow(f\"Left {img_left}\", imLeft)\n",
    "                #cv2.imshow(f\"Right {img_right}\", imRight)\n",
    "                #k = cv2.waitKey(0)\n",
    "\n",
    "            \n",
    "                # Destroy windows automatically on any key press\n",
    "                if k is not None:\n",
    "                    cv2.destroyWindow(f\"Left {img_left}\")\n",
    "                    cv2.destroyWindow(f\"Right {img_right}\")\n",
    "            \n",
    "            except:\n",
    "                if imgL is None:\n",
    "                    print(f\"[!]Couldn't load L-image: {img_left}\")\n",
    "                if imgR is None:\n",
    "                    print(f\"[!]Couldn't load R-image: {img_right}\")\n",
    "                continue\n",
    "        print(\"---------------------\\n[+] Finished viewing initial samples.\")\n",
    "        return lstPass\n",
    "        \n",
    "    \n",
    "    \n",
    "    def frameFromLR(self):\n",
    "        ### TODO: Will have to refer to the 14th paper later\n",
    "        ### For now standard\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def removeNoise(self):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def createVideo(self):\n",
    "        try:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "            video = cv2.VideoWriter('out_video.avi', fourcc, 30.0, (588,320))\n",
    "        \n",
    "            for imgL, imgR in self.sampleImages:\n",
    "                video.write(imgL)\n",
    "\n",
    "            video.release()\n",
    "            cv2.destroyAllWindows()\n",
    "            print(f\"[+]Video Released\")\n",
    "            \n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "            print(f\"Possible fixes:\\n1. See if DIVX is compatible with your machine\\n2. Use a media player that supports .avi\\n\\\n",
    "                    3. Match the shape of frames with the video\")\n",
    "\n",
    "    \n",
    "    \n",
    "    def detectPedestrians(self, img): \n",
    "        '''\n",
    "            Brief: \n",
    "                    Standard Histogram Oriented Gradients Object Detection provided by openCV. \n",
    "                    (Dalal & Triggs)\n",
    "            \n",
    "            Param:\n",
    "                    frame -> For which pedestrian detection must be done\n",
    "                    \n",
    "            Returns:\n",
    "                    Frame with a green bounding box around pedestrians\n",
    "        '''\n",
    "        hog = cv2.HOGDescriptor()\n",
    "        hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "        \n",
    "        if img is None:\n",
    "            img = cv2.imread(\"C:\\\\Users\\\\HP\\\\Desktop\\\\Research\\\\Trajectory_Markov_Research\\\\Implementations\\\\Dataset_Dailmer\\\\Data\\\\TrainingData\\\\2012-06-05_165931\\\\RectGrabber\\\\imgrect_000000227_c0.pgm\")\n",
    "        \n",
    "        img = cv2.resize(img, (600, 450))\n",
    "        (rects, weights) = hog.detectMultiScale(img, winStride=(4, 4), padding=(16, 16), scale=1.2)\n",
    "\n",
    "        font                   = cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "        fontScale              = 0.7\n",
    "        fontColor              = (255, 255, 255)\n",
    "        lineType               = 2\n",
    "\n",
    "        for (x, y, w, h) in rects:\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(img,'Person', (x,y), font, fontScale,fontColor,lineType)\n",
    "\n",
    "        cv2.imshow(\"Bounding Boxes\", img)\n",
    "        cv2.waitKey(0)\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        ### Change filepath according to your machine config\n",
    "        self.trainDataPath = \"C:\\\\Users\\\\HP\\\\Desktop\\\\Research\\\\Trajectory_Markov_Research\\\n",
    "                                \\\\Implementations\\Dataset_Dailmer\\\\Data\\\\TrainingData\\\\\"\n",
    "        self.processedData = self.readData(self.trainDataPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model:\n",
    "    '''\n",
    "    Brief:\n",
    "        Goal Directed Pedestrian Prediction \n",
    "        (A markovian approach for pedestrian trajectory prediction)\n",
    "        \n",
    "    Receives:\n",
    "        Pre-processed and pedestrain detected data from preProcessData class\n",
    "        \n",
    "    Returns:\n",
    "        Predicted Trajectory of each pedestrian in scene\n",
    "                \n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class analytics:\n",
    "    '''\n",
    "    Brief:\n",
    "        Analyzes predicted trajectories against ground truth.\n",
    "        \n",
    "    Receives:\n",
    "        Predicted trajectories from model class\n",
    "        \n",
    "    Displays:\n",
    "        Accuracy and evaluation metrics. And other visual-aids for analysis of the model\n",
    "                \n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create instances here :)\n",
    "#df = preProcessData()                       # Remove noise, use paper 14, Detect pedestrians(HOG) and then pass to model\n",
    "#predicted_df= model(df.processedData)\n",
    "#analytics(predicted_df.preds)\n",
    "\n",
    "\n",
    "#if img.shape != (64, 128):\n",
    "#    img = cv2.resize(img, (64, 128))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
